---
title: "HW 4"
author: "Student Name"
date: "10/10/2024"
output: 
  html_document:
    number_sections: true
---

This homework is designed to give you practice working with statistical/philosophical measures of fairness. 

#
The paper linked below^[https://link.springer.com/article/10.1007/s00146-023-01676-3] discusses potential algorithmic bias in the context of credit.  In particular, banks are now regularly using machine learning algorithms to do an initial screening for credit-worthy loan applicants.  In section 4.5.2, this paper reports the rates at which various racial groups were granted a mortgage.  If we assume that it is a classifier making these predictions^[It is unclear whether this is an algorithm producing these predictions or human] what additional information would be necessary to assess this classifier according to equalized odds?

We would need information about the protected group (Race in this situation) and information about the true positive rates and false positive rates. This means we need the true outcomes and classifier predictions as well.  

#
Show or argue that the impossibility result discussed in class does not hold when our two fringe cases^[a) perfect predicting classifier and b) perfectly equal proportions of ground truth class labels across the protected variable] are met.  

a) The impossibility result does not hold because there is no conflict between between the fairness criteria as a perfect predictor will remove the imperfections and equal base rates.

b) Since we satisfy equalized odds due to equal positive and negative rates and calibration and demographic parity, the impossibility result does not hold due to equal base rates.

#

How would Rawls's Veil of Ignorance define a protected class?  Further, imagine that we preprocessed data by removing this protected variable from consideration before training out algorithm.  How could this variable make its way into our interpretation of results nonetheless?

Even if we remove the protected variable from training, it can still influence it through correlated variables. As a result, the model can still produce unfair results even if we preprocess.


#

Based on all arguments discussed in class, is the use of COMPAS to supplement a judge's discretion justifiable.  Defend your position.  This defense should appeal to statistical and philosophical measures of fairness as well as one of our original moral frameworks from the beginning of the course.  Your response should be no more than a paragraph in length. 

It is not justifiable as it compromises statistical and philosophical fairness. Philosophically, a tool like this should be rejected as it perpetuates systemic inequalities found in our society already. Even if we remove protect variables we still run the risk of correlated variables influencing the impact of the model. Statistically, it violates equalized odds as it exhibits unequal false positive and false negative outcomes.